# Advanced Dual-Agent RAG Platform for Insurance Document Intelligence

A comprehensive, modular RAG (Retrieval-Augmented Generation) system designed specifically for insurance document processing and intelligent query resolution. Built with Django REST Framework backend and Streamlit frontend, featuring dual-agent architecture (Traditional + ReAct), deterministic premium calculations, and advanced document comparison capabilities.

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Django](https://img.shields.io/badge/Django-5.1.4-green.svg)](https://www.djangoproject.com/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.40.2-red.svg)](https://streamlit.io/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE.txt)

---

## ğŸ¯ Quick Overview

**Two Cognitive Approaches, One Platform:**

| Approach | Speed | Best For | Architecture |
|----------|-------|----------|--------------|
| **Traditional Orchestrator** | ~3-5s | Simple queries, quick answers | Single-step routing |
| **ReAct Agentic** | ~5-15s | Complex reasoning, multi-step | Thoughtâ†’Actionâ†’Observation loop |

**Example Query**: *"Calculate premium for 2 adults aged 32, 45 with â‚¹10L coverage"*
- **Traditional**: Routes to Premium Calculator â†’ Returns answer (3s)
- **ReAct**: Analyzes query â†’ Identifies needed tools â†’ Calls calculator â†’ Validates â†’ Returns structured answer (8s)

---

## âœ¨ Key Features

- ğŸ¤– **Dual-Agent System**: Choose speed vs depth
- ğŸ§® **Smart Premium Calculator**: Excel-based with 15+ configurations
- ğŸ“Š **Multi-Product Comparison**: Side-by-side policy analysis
- ğŸ” **Advanced Document Search**: Semantic chunking + ChromaDB
- ğŸ“ˆ **Real-Time Evaluation**: 3D quality metrics (coverage, similarity, diversity)
- âœ… **35+ Test Cases**: Comprehensive testing across 6 modules

---

## ğŸ—ï¸ Architecture

### Dual-Agent System Architecture

The system offers **two complementary query execution paths**, each optimized for different use cases:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Frontend Layer                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Ingestion UI      â”‚  â”‚  Traditional UI    â”‚  â”‚  ReAct UI     â”‚  â”‚
â”‚  â”‚  (Streamlit)       â”‚  â”‚  (Streamlit)       â”‚  â”‚  (Streamlit)  â”‚  â”‚
â”‚  â”‚  Port: 8501        â”‚  â”‚  Port: 8502        â”‚  â”‚  Port: 8503   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                        â”‚                      â”‚
              â”‚          HTTP REST API                        â”‚
              â”‚                        â”‚                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Django Backend (Port: 8000)                       â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚            TWO INDEPENDENT QUERY SYSTEMS                        â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚  SYSTEM 1:                      â”‚    SYSTEM 2:                  â”‚  â”‚
â”‚  â”‚  Traditional Orchestrator       â”‚    ReAct Agentic System       â”‚  â”‚
â”‚  â”‚  (/agents/query/)               â”‚    (/agents/agentic/query/)   â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚  â€¢ Single-step routing          â”‚    â€¢ Iterative reasoning      â”‚  â”‚
â”‚  â”‚  â€¢ Intent classification        â”‚    â€¢ Thoughtâ†’Actionâ†’Observe   â”‚  â”‚
â”‚  â”‚  â€¢ ONE agent per query          â”‚    â€¢ Multi-tool chaining      â”‚  â”‚
â”‚  â”‚  â€¢ Fast (3-5s)                  â”‚    â€¢ Comprehensive (5-15s)    â”‚  â”‚
â”‚  â”‚  â€¢ Direct agent selection       â”‚    â€¢ Dynamic tool selection   â”‚  â”‚
â”‚  â”‚                                 â”‚    â€¢ Learning classifier      â”‚  â”‚
â”‚  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”´â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚      â”‚              â”‚          â”‚         â”‚                             â”‚
â”‚  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â”€â” â”Œâ”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚Retrieval â”‚  â”‚ Premium  â”‚ â”‚Comparâ”‚ â”‚  ReAct Agent + Tools    â”‚    â”‚
â”‚  â”‚  Agent   â”‚  â”‚Calculatorâ”‚ â”‚ison  â”‚ â”‚  (Dynamic Reasoning     â”‚    â”‚
â”‚  â”‚          â”‚  â”‚  Agent   â”‚ â”‚Agent â”‚ â”‚   with Learning)        â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                  Service Layer (Shared)                       â”‚  â”‚
â”‚  â”‚  â€¢ Document Retriever  â€¢ Excel Parser  â€¢ Response Builder   â”‚  â”‚
â”‚  â”‚  â€¢ Query Enhancer      â€¢ Age Matcher   â€¢ Premium Comparator  â”‚  â”‚
â”‚  â”‚  â€¢ Memory Manager      â€¢ Conversation  â€¢ Document Comparator â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                   Core Services                               â”‚  â”‚
â”‚  â”‚  â€¢ Ingestion API   â€¢ Chunking Service  â€¢ Logging Utility    â”‚  â”‚
â”‚  â”‚  â€¢ Retrieval API   â€¢ Embedding Service â€¢ Evaluation Engine   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                                â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Azure OpenAI       â”‚        â”‚    ChromaDB         â”‚
    â”‚  â€¢ Embeddings Model  â”‚        â”‚  â€¢ Vector Store     â”‚
    â”‚  â€¢ Chat Model        â”‚        â”‚  â€¢ Collections      â”‚
    â”‚  â€¢ Reasoning LLM     â”‚        â”‚  â€¢ Metadata Filter  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ¯ System Comparison

| Feature | Traditional Orchestrator | ReAct Agentic System |
|---------|-------------------------|----------------------|
| **Query Complexity** | Simple, single-objective | Complex, multi-step |
| **Execution Pattern** | One-shot routing | Iterative reasoning loop |
| **Tool Usage** | ONE tool per query | MULTIPLE tools chained |
| **LLM Invocations** | 1-2 calls | 3-10+ calls |
| **Response Time** | 3-5 seconds | 5-15 seconds |
| **Transparency** | Intent + Result | Full reasoning trace |
| **Learning Capability** | Static classification | Pattern learning enabled |
| **Best For** | Standard Q&A, calculations | Multi-step workflows |
| **Interface** | Port 8502 | Port 8503 |

### ğŸ“Š When to Use Each System

**Use Traditional Orchestrator (/agents/query/) when:**
- âœ… Query has single, clear objective
- âœ… Speed is priority
- âœ… Standard document Q&A
- âœ… Simple premium calculations
- âœ… Direct product comparisons

**Use ReAct Agentic System (/agents/agentic/query/) when:**
- ğŸ¤– Query requires multiple sequential steps
- ğŸ¤– Need to chain tools together
- ğŸ¤– Want visibility into reasoning process
- ğŸ¤– Complex decision-making with conditional logic
- ğŸ¤– Exploratory analysis across multiple data sources

### ğŸ”„ ReAct Iterative Reasoning Flow

```
Query: "Calculate premium for age 35, then compare with ActivFit"

Iteration 1:
  ğŸ’­ THOUGHT: "I need to calculate premium first"
  ğŸ”§ ACTION: premium_calculator(age=35, sum_insured=500000)
  ğŸ‘ï¸ OBSERVATION: "Premium calculated: â‚¹15,000"

Iteration 2:
  ğŸ’­ THOUGHT: "Now I need ActivFit premium for comparison"
  ğŸ”§ ACTION: document_retriever(query="ActivFit premium age 35", k=3)
  ğŸ‘ï¸ OBSERVATION: "ActivFit: â‚¹12,000 for age 35"

Iteration 3:
  ğŸ’­ THOUGHT: "I have both results, can provide comparison"
  ğŸ”§ ACTION: finish
  âœ… FINAL_ANSWER: "Your premium: â‚¹15,000. ActivFit is â‚¹3,000 cheaper at â‚¹12,000."

Metadata: 3 iterations, 2 tools used, 8.7s execution time
```

---

## ğŸ› ï¸ Technology Stack

### Backend Technologies
- **Framework**: Django 5.1.4 with Django REST Framework 3.15.2
- **Database**: SQLite (development) / PostgreSQL-compatible (scalable deployment)
- **Vector Store**: ChromaDB 0.5.23
- **AI/ML**: 
  - LangChain 0.3.27 & LangChain-OpenAI 0.2.11
  - scikit-learn 1.5.2 (semantic chunking)
- **Document Processing**: 
  - pdfplumber 0.11.4 (PDF parsing)
  - pandas 2.2.3 (table manipulation)
- **API**: RESTful API with CORS support (django-cors-headers 4.6.0)

### Frontend Technologies
- **UI Framework**: Streamlit 1.40.2
- **HTTP Client**: requests 2.32.3
- **Configuration**: python-dotenv 1.0.1

### Infrastructure & Tools
- **AI Provider**: Azure OpenAI (embeddings & chat completion)
- **Logging**: Comprehensive file & console logging
- **Environment**: Virtual environment (venv)
- **Version Control**: Git

---

## ğŸ“¦ Prerequisites

- **Python 3.11+**, 8GB+ RAM recommended
- **Azure OpenAI**: Embedding & chat model deployments with API keys
- **Git** and modern browser for Streamlit UIs

---

## ğŸš€ Quick Start

```bash
# 1. Clone and setup
git clone https://github.com/Yuvaranjani123/rag_module_1.git
cd rag_module_1
python -m venv venv
venv\Scripts\Activate.ps1  # Windows PowerShell
# source venv/bin/activate  # macOS/Linux

# 2. Install dependencies
pip install -r requirements.txt

# 3. Configure environment
cp .env.example .env
# Edit .env with your Azure OpenAI credentials

# 4. Setup database
cd backend
python manage.py migrate
cd ..
```

**Key Environment Variables** (in `.env`):
```ini
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_KEY=your-api-key
AZURE_OPENAI_TEXT_DEPLOYMENT_EMBEDDINGS=text-embedding-ada-002
AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-35-turbo
DJANGO_SECRET_KEY=generate-using-django-command
API_BASE=http://localhost:8000
```

---

## ğŸƒ Usage Guide

### Start Services

```bash
# Terminal 1: Backend API
cd backend
python manage.py runserver  # http://localhost:8000

# Terminal 2: Document Ingestion
streamlit run frontend/ingestion_run.py --server.port 8501

# Terminal 3: Traditional Query Interface (Fast, 3-5s)
streamlit run frontend/retrieval_run.py --server.port 8502

# Terminal 4: ReAct Agentic Interface (Comprehensive, 5-15s)
streamlit run frontend/agentic_run.py --server.port 8503
```

### Choose Your Interface

| Interface | Port | Purpose | Use When |
|-----------|------|---------|----------|
| **Ingestion** | 8501 | Upload & process PDFs/Excel | Setting up document collections |
| **Traditional** | 8502 | Fast single-objective queries | "What is covered?", "Calculate premium" |
| **ReAct Agent** | 8503 | Complex multi-step reasoning | "Calculate, compare, recommend best" |

**Example Workflows:**

**Traditional (Port 8502)** - Single objective:
```
"What is the maternity coverage in ActivAssure?"
â†’ Direct retrieval â†’ Answer in 3-5s
```

**ReAct Agent (Port 8503)** - Multi-step:
```
"Calculate premium for age 35, then compare with ActivFit"
â†’ Iteration 1: Calculate premium â†’ â‚¹15,000
â†’ Iteration 2: Query ActivFit â†’ â‚¹12,000
â†’ Final: "ActivFit is â‚¹3,000 cheaper"
Total time: 8s, 2 iterations
```

---


## ğŸ“¡ API Endpoints (Summary)

**Base URL**: `http://localhost:8000`

### Key Endpoints

| Endpoint | Method | Purpose |
|----------|--------|---------|  
| `/agents/query/` | POST | Traditional orchestrator (fast, single-step) |
| `/agents/agentic/query/` | POST | ReAct agent (multi-step reasoning) |
| `/ingestion/upload/` | POST | Upload PDF documents |
| `/ingestion/collections/` | GET | List document collections |
| `/retriever/query/` | POST | Direct document retrieval |

**Example Request (Traditional)**:
```json
POST /agents/query/
{
  "query": "What is maternity coverage?",
  "collection_name": "ActivAssure",
  "k": 3
}
```
---
## ğŸ“ Project Structure


```
rag_module/
â”œâ”€â”€ backend/                          # Django REST API Backend
â”‚   â”œâ”€â”€ agents/                       # ğŸ¤– Multi-Agent System
â”‚   â”‚   â”œâ”€â”€ retrieval_agent.py       # Document Q&A agent with memory
â”‚   â”‚   â”œâ”€â”€ comparison_agent.py      # Multi-product comparison agent
â”‚   â”‚   â”œâ”€â”€ orchestrator.py          # Intelligent query routing
â”‚   â”‚   â”œâ”€â”€ views.py                 # Agent API endpoints
â”‚   â”‚   â”œâ”€â”€ urls.py                  # Agent URL routing
â”‚   â”‚   â”œâ”€â”€ calculators/             # Premium calculation modules
â”‚   â”‚   â”‚   â”œâ”€â”€ calculator_base.py   # Main calculator orchestration
â”‚   â”‚   â”‚   â”œâ”€â”€ excel_parser.py      # Excel workbook parsing
â”‚   â”‚   â”‚   â”œâ”€â”€ age_matcher.py       # Age band matching logic
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py          # Calculator exports
â”‚   â”‚   â”œâ”€â”€ retrievers/              # Document retrieval modules
â”‚   â”‚   â”‚   â”œâ”€â”€ document_retriever.py   # ChromaDB document search
â”‚   â”‚   â”‚   â”œâ”€â”€ query_enhancer.py       # Query preprocessing
â”‚   â”‚   â”‚   â”œâ”€â”€ conversation_memory.py  # Session management
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ comparators/             # Comparison modules
â”‚   â”‚       â”œâ”€â”€ document_comparator.py  # Document-based comparison
â”‚   â”‚       â”œâ”€â”€ premium_comparator.py   # Premium comparison logic
â”‚   â”‚       â”œâ”€â”€ response_builder.py     # Answer formatting
â”‚   â”‚       â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ backend/                      # Django project configuration
â”‚   â”‚   â”œâ”€â”€ settings.py              # âš™ï¸ Django settings & CORS
â”‚   â”‚   â”œâ”€â”€ urls.py                  # Main URL routing
â”‚   â”‚   â”œâ”€â”€ wsgi.py                  # WSGI application entry
â”‚   â”‚   â””â”€â”€ asgi.py                  # ASGI application entry
â”‚   â”œâ”€â”€ config/                       # Configuration modules
â”‚   â”‚   â”œâ”€â”€ prompt_config.py         # AI prompt templates
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ evaluation/                   # ğŸ“Š Evaluation metrics
â”‚   â”‚   â”œâ”€â”€ metrics.py               # Retrieval quality metrics
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ ingestion/                    # ğŸ“„ Document ingestion app
â”‚   â”‚   â”œâ”€â”€ views.py                 # Ingestion API endpoints
â”‚   â”‚   â”œâ”€â”€ service.py               # Chunking & embedding service
â”‚   â”‚   â”œâ”€â”€ utils.py                 # PDF processing utilities
â”‚   â”‚   â”œâ”€â”€ models.py                # Data models
â”‚   â”‚   â”œâ”€â”€ urls.py                  # URL routing
â”‚   â”‚   â””â”€â”€ migrations/              # Database migrations
â”‚   â”œâ”€â”€ retriever/                    # ğŸ” Document retrieval app
â”‚   â”‚   â”œâ”€â”€ views.py                 # Retrieval API endpoints
â”‚   â”‚   â”œâ”€â”€ models.py                # Data models
â”‚   â”‚   â”œâ”€â”€ urls.py                  # URL routing
â”‚   â”‚   â””â”€â”€ migrations/              # Database migrations
â”‚   â”œâ”€â”€ logs/                         # ğŸ“ Logging utilities
â”‚   â”‚   â”œâ”€â”€ utils.py                 # Logging configuration
â”‚   â”‚   â”œâ”€â”€ models.py                # Log models
â”‚   â”‚   â”œâ”€â”€ app.log                  # Application logs (generated)
â”‚   â”‚   â””â”€â”€ migrations/              # Database migrations
â”‚   â”œâ”€â”€ utils/                        # Shared utilities
â”‚   â”œâ”€â”€ media/                        # Media file storage
â”‚   â”‚   â””â”€â”€ logs/                    # Premium workbook registry
â”‚   â”‚       â””â”€â”€ activ_assure_premium_chart.xlsx
â”‚   â”œâ”€â”€ manage.py                    # Django management script
â”‚   â””â”€â”€ db.sqlite3                   # SQLite database
â”‚
â”œâ”€â”€ frontend/                         # ğŸ¨ Streamlit UI (Modularized)
â”‚   â”œâ”€â”€ ingestion_run.py             # ğŸ“¥ Document ingestion UI (238 lines)
â”‚   â”œâ”€â”€ retrieval_run.py             # ğŸ” Document retrieval UI
â”‚   â”œâ”€â”€ services/                    # Business logic services
â”‚   â”‚   â”œâ”€â”€ api_client.py            # Backend API communication (190 lines)
â”‚   â”‚   â”œâ”€â”€ ingestion_pipeline.py   # Ingestion orchestration (305 lines)
â”‚   â”‚   â””â”€â”€ file_manager.py          # File operations (150 lines)
â”‚   â””â”€â”€ components/                  # Reusable UI components
â”‚       â””â”€â”€ ingestion/
â”‚           â”œâ”€â”€ file_uploader.py     # Upload UI components
â”‚           â”œâ”€â”€ pdf_processor.py     # PDF workflow UI (330 lines)
â”‚           â””â”€â”€ zip_processor.py     # Batch processing UI (400+ lines)
â”‚
â”œâ”€â”€ media/                            # ğŸ’¾ File storage (auto-created)
â”‚   â”œâ”€â”€ input/                       # Uploaded PDF files
â”‚   â”œâ”€â”€ output/                      # Processed files
â”‚   â”‚   â”œâ”€â”€ [ProductName]/           # Product-specific output
â”‚   â”‚   â”‚   â”œâ”€â”€ table_*.csv          # Extracted tables
â”‚   â”‚   â”‚   â”œâ”€â”€ page_*_text.txt      # Extracted text
â”‚   â”‚   â”‚   â”œâ”€â”€ table_file_map.csv   # Table mapping
â”‚   â”‚   â”‚   â””â”€â”€ all_chunks_preview.txt
â”‚   â”‚   â”œâ”€â”€ chroma_db/               # Vector databases
â”‚   â”‚   â”‚   â””â”€â”€ [ProductName]/       # Product-specific ChromaDB
â”‚   â”‚   â”‚       â”œâ”€â”€ chroma.sqlite3   # ChromaDB SQLite
â”‚   â”‚   â”‚       â””â”€â”€ [collection_id]/ # Collection data
â”‚   â”‚   â””â”€â”€ temp/                    # Temporary extraction folder
â”‚   â””â”€â”€ logs/                        # Log files
â”‚
â”œâ”€â”€ scripts/                          # Utility scripts
â”œâ”€â”€ venv/                            # Python virtual environment
â”œâ”€â”€ .env                             # Environment variables (create from .env.example)
â”œâ”€â”€ .env.example                     # Environment template
â”œâ”€â”€ .gitignore                       # Git ignore rules
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ run_tests.py                     # ğŸ§ª Test runner with colored output
â”œâ”€â”€ LICENSE.txt                      # MIT License
â”œâ”€â”€ README.md                        # This file
â”œâ”€â”€ PUBLICATION_GUIDE.md             # Publication guidelines
â”œâ”€â”€ INSURANCE_RAG_PUBLICATION.md     # Project publication documentation
â”œâ”€â”€ TESTING_GUIDE.md                 # Comprehensive testing documentation
â”œâ”€â”€ TESTING_QUICK_REFERENCE.md       # Quick command reference
â””â”€â”€ HOW_TO_ADD_YOUR_OWN_TESTS.md     # Guide for writing new tests
```

### Key Directory Descriptions

| Directory | Purpose | Key Files |
|-----------|---------|-----------|
| `backend/agents/` | Multi-agent system core | `orchestrator.py`, `retrieval_agent.py`, `comparison_agent.py` |
| `backend/agents/calculators/` | Premium calculation engine | `calculator_base.py`, `excel_parser.py`, `age_matcher.py` |
| `backend/ingestion/` | Document processing pipeline | `service.py` (chunking), `utils.py` (PDF parsing) |
| `backend/ingestion/tests/` | Ingestion module tests | `test_views.py`, `test_service.py`, `test_utils.py` |
| `backend/retriever/` | Vector search & retrieval | `views.py` (query endpoints) |
| `backend/retriever/tests/` | Retriever module tests | `test_views.py`, `test_internal.py`, `test_evaluator.py` |
| `backend/evaluation/` | Quality metrics | `metrics.py` (term coverage, diversity, similarity) |
| `backend/logs/` | Logging infrastructure | `utils.py` (logging setup), `app.log` (logs) |
| `frontend/services/` | Business logic layer | `api_client.py`, `ingestion_pipeline.py`, `file_manager.py` |
| `frontend/components/` | Reusable UI components | `pdf_processor.py`, `zip_processor.py` |
| `media/output/chroma_db/` | Vector databases | Per-product ChromaDB collections |

---

## ğŸ§ª Testing

### Comprehensive Test Suite

The project includes a robust testing infrastructure with 35+ test cases covering ingestion, retrieval, and agent modules. All tests are organized in a modular structure with files under 500 lines for maintainability.

#### Test Organization

```
backend/
â”œâ”€â”€ ingestion/tests/          # Ingestion module tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_views.py        # API endpoint tests (~250 lines)
â”‚   â”œâ”€â”€ test_service.py      # ChunkerEmbedder tests (~130 lines)
â”‚   â””â”€â”€ test_utils.py        # Utility function tests (~80 lines)
â””â”€â”€ retriever/tests/          # Retriever module tests
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_views.py         # API endpoint tests (~180 lines)
    â”œâ”€â”€ test_internal.py      # Internal query tests (~180 lines)
    â””â”€â”€ test_evaluator.py     # Evaluation tests (~80 lines)
```

#### Running Tests

**Quick Start:**
```bash
# Run all tests
python run_tests.py

# Run tests with verbose output
python run_tests.py --verbose

# Run with coverage report
python run_tests.py --coverage

# Run specific module tests
python run_tests.py ingestion
python run_tests.py retriever

# Run specific test file
python run_tests.py ingestion.tests.test_views

# Run specific test class
python run_tests.py ingestion.tests.test_views.PDFUploadAPITests

# Run specific test method
python run_tests.py ingestion.tests.test_views.PDFUploadAPITests.test_upload_pdf_success
```

**Using Django's test command directly:**
```bash
cd backend
python manage.py test
python manage.py test ingestion.tests
python manage.py test ingestion.tests.test_views.PDFUploadAPITests
```

#### Test Coverage

| Module | Test Files | Test Count | Coverage Areas |
|--------|-----------|------------|----------------|
| **Ingestion** | 3 files | 20+ tests | PDF upload, table extraction, text extraction, chunking |
| **Retriever** | 3 files | 15+ tests | Query processing, evaluation metrics, filtering |
| **Total** | 6 files | 35+ tests | Full API and service layer coverage |

#### Key Test Features

- **Modular Organization**: Tests split into focused files (<300 lines each)
- **Comprehensive Mocking**: External services (Azure OpenAI, ChromaDB) properly mocked
- **API Testing**: Complete coverage of REST endpoints
- **Service Testing**: Unit tests for core business logic
- **Utility Testing**: Tests for helper functions and utilities
- **Colored Output**: Easy-to-read test results with visual indicators

#### Testing Documentation

For detailed testing information, see:
- **TESTING_GUIDE.md**: Complete beginner's guide to testing concepts and practices
- **TESTING_QUICK_REFERENCE.md**: Command reference and troubleshooting
- **HOW_TO_ADD_YOUR_OWN_TESTS.md**: Step-by-step guide for writing new tests

#### Example Test Output

```
============================================================
                   RAG Module Test Runner
============================================================

Running: All Tests
Command: python.exe manage.py test --verbosity=1 --keepdb
Found 35 test(s).
Using existing test database for alias 'default'...
...................................
--------------------------------------------------------------
Ran 35 tests in 0.245s

OK
Preserving test database for alias 'default'...

============================================================
âœ… All tests passed!
============================================================
```

---

## ğŸ› Troubleshooting

### Common Issues & Solutions

#### 1. Django Server Won't Start

**Symptoms**:
- "Port 8000 is already in use"
- "ModuleNotFoundError"
- Import errors

**Solutions**:
```bash
# Check if port is in use
netstat -ano | findstr :8000  # Windows
lsof -i :8000                 # macOS/Linux

# Kill process using port
taskkill /PID <PID> /F        # Windows
kill -9 <PID>                 # macOS/Linux

# Verify virtual environment
which python                   # Should point to venv
pip list                       # Check installed packages

# Reinstall dependencies
pip install -r requirements.txt --force-reinstall
```

#### 2. Streamlit Connection Errors

**Symptoms**:
- "Connection refused to http://localhost:8000"
- "CORS policy blocked"

**Solutions**:
```python
# Check Django CORS settings (backend/settings.py)
CORS_ALLOWED_ORIGINS = [
    "http://localhost:8501",
    "http://localhost:8502",
]

# Verify Django is running
curl http://localhost:8000/api/  # Should return API response

# Check API_BASE in .env
API_BASE=http://localhost:8000  # No trailing slash
```

#### 3. Azure OpenAI Errors

**Symptoms**:
- "Invalid API key"
- "Deployment not found"
- "Rate limit exceeded"

**Solutions**:
```bash
# Verify credentials in .env
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_KEY=<your-key>

# Check deployment names
az cognitiveservices account deployment list \
  --name <your-resource-name> \
  --resource-group <your-rg>

# Monitor quota
# Azure Portal â†’ Your Resource â†’ Quotas

# Implement retry logic (already included)
# Check logs/app.log for details
```

#### 4. ChromaDB Issues

**Symptoms**:
- "Collection not found"
- "Dimension mismatch"
- "PersistentClient error"

**Solutions**:
```bash
# Clear ChromaDB cache
rm -rf media/output/chroma_db/*  # âš ï¸ Deletes all data

# Check directory permissions
ls -la media/output/chroma_db/

# Verify embedding model
# Ensure AZURE_OPENAI_TEXT_DEPLOYMENT_EMBEDDINGS matches actual deployment

# Check ChromaDB version compatibility
pip show chromadb
```

#### 5. PDF Processing Errors

**Symptoms**:
- "No tables found" (when tables exist)
- Garbled text extraction
- Encoding errors

**Solutions**:
```python
# Verify PDF is not scanned image
# Use OCR for scanned documents (not included in this version)

# Check pdfplumber installation
pip install --upgrade pdfplumber

# Adjust table detection settings
# Edit backend/ingestion/utils.py:
table_settings = {
    "vertical_strategy": "lines",
    "horizontal_strategy": "lines",
    "min_words_vertical": 3,
    "min_words_horizontal": 1,
}
```

#### 6. Memory Issues with Large Documents

**Symptoms**:
- "MemoryError"
- Process killed
- Slow processing

**Solutions**:
```bash
# Increase available memory
# Reduce batch size in chunking

# Process documents in smaller batches
# Split large PDFs into sections

# Monitor memory usage
top              # macOS/Linux
Task Manager     # Windows
```

### Debug Mode

Enable comprehensive logging:

```python
# .env file
DEBUG=True
LOG_LEVEL=DEBUG

# Check logs
tail -f backend/logs/app.log  # macOS/Linux
Get-Content backend/logs/app.log -Wait  # PowerShell
```

### Health Check Commands

```bash
# Django health check
python backend/manage.py check

# Test database
python backend/manage.py showmigrations

# Test imports
python -c "import chromadb, langchain, pdfplumber, pandas; print('OK')"

# Test Azure OpenAI connection
python -c "
from langchain_openai import AzureOpenAIEmbeddings
import os
from dotenv import load_dotenv
load_dotenv()
embeddings = AzureOpenAIEmbeddings()
result = embeddings.embed_query('test')
print(f'Embedding dimension: {len(result)}')
"
```

---

## ğŸ“Š Performance Benchmarks

### Comprehensive Performance Metrics

| Component | Metric | Value | Notes |
|-----------|--------|-------|-------|
| **Document Ingestion** ||||
| Table Extraction | Speed | 30-45s/page | PDF complexity dependent |
| Table Extraction | Accuracy | 85-90% | Manual review recommended for complex tables |
| Text Extraction | Speed | 10-15s/page | Excluding tables |
| Semantic Chunking | Duration | 8-15 minutes | For 25-page document |
| Embedding Generation | Duration | 2-3 minutes | ChromaDB insert included |
| **Full Pipeline** | **Total Time** | **15-20 minutes** | Complete document processing |
| **Query Performance** ||||
| Traditional Orchestrator | Average | 3.5 seconds | Single-step retrieval |
| Traditional Orchestrator | P95 | 5 seconds | 95th percentile |
| ReAct (Simple Query) | Average | 6 seconds | 2-3 tool calls |
| ReAct (Simple Query) | P95 | 10 seconds | 95th percentile |
| ReAct (Complex Query) | Average | 12 seconds | 4-5 tool calls, multi-step reasoning |
| ReAct (Complex Query) | P95 | 15 seconds | 95th percentile |
| **Quality Metrics** ||||
| Test Coverage | Test Cases | 35+ tests | Across 13 test classes |
| Test Coverage | Modules | 6 modules | Ingestion, retrieval, agents |
| Evaluation Metrics | Dimensions | 3D assessment | Term coverage, similarity, diversity |
| Intent Classification | Accuracy | High | Pattern-based with learning capability |

**Performance Notes:**
- ReAct system is intentionally slower due to multi-step reasoning (provides more comprehensive answers)
- Semantic chunking overhead is offset by improved retrieval quality
- Table detection accuracy improves with well-structured PDFs

---

## âš ï¸ Known Limitations

### Technical Limitations

**1. ReAct Agent Constraints**
- Maximum 10 reasoning iterations per query (prevents infinite loops)
- Complex multi-product comparisons may require iteration limit tuning
- No conversation history persistence across sessions

**2. Document Processing**
- Table detection accuracy: 85-90% (not 100%)
  - Complex nested tables may require manual review
  - Merged cells and irregular layouts can affect extraction
- PDF format requirements: Text-based PDFs only (no scanned images without OCR)
- Semantic chunking overhead: 8-15 minutes for large documents

**3. Query Processing**
- Query length limit: 1000 characters (enforced in API)
- Single language support: English only (embeddings and LLM optimized for English)
- Intent classification: Pattern-based, may misclassify edge cases
- Token context window: Limited by Azure OpenAI model (gpt-4/gpt-35-turbo limits)

**4. Data & Storage**
- ChromaDB: Single instance, not distributed (limited scalability)
- SQLite: Development database only, not suitable for high-concurrency scenarios
- Embedding storage: Grows linearly with document corpus size
- No automatic document versioning or update detection

---

### Performance Limitations

**1. Response Time Trade-offs**
- ReAct system 2-4x slower than Traditional (by design for thorough reasoning)
- Semantic chunking adds 8-15 minutes to ingestion pipeline
- Azure OpenAI API latency dependent on service region and load

**2. Concurrent Processing**
- Single-instance deployment limits concurrent request handling
- No built-in queue management for multiple simultaneous ingestions
- ChromaDB write operations are blocking

**3. Rate Limits**
- Azure OpenAI quota restrictions apply (Tokens Per Minute, Requests Per Minute)
- Embedding API calls rate-limited by Azure subscription tier
- No built-in retry logic for rate limit errors

---

### Deployment Limitations

**1. Infrastructure Dependencies**
- Azure OpenAI subscription required (vendor lock-in)
- Active internet connection needed for all LLM operations
- No offline mode or local LLM fallback

**2. Scalability Constraints**
- SQLite: Single-file database, not suitable for distributed deployment
- ChromaDB: File-based storage, requires shared filesystem for horizontal scaling
- No built-in load balancing or service discovery

**3. Security & Access Control**
- No built-in user authentication or authorization system
- No role-based access control (RBAC) for documents or features
- API endpoints not secured by default (requires additional implementation)
- No audit logging for compliance requirements

**4. Monitoring & Observability**
- Limited built-in logging and monitoring
- No distributed tracing across components
- No performance metrics dashboard (beyond Streamlit UI metrics)
- Manual log file analysis required for troubleshooting

---

### Functional Limitations

**1. Document Support**
- PDF only (no Word, Excel, or other formats for ingestion)
- Premium calculator Excel format specific to ActivAssure structure
- No automatic document format detection or conversion

**2. Multi-tenancy**
- No built-in support for multiple organizations or user isolation
- ChromaDB collections not segregated by user/tenant
- Shared embedding space across all documents

**3. Advanced Features Not Included**
- No document update/versioning system
- No incremental indexing (full re-ingestion required)
- No multi-language support
- No image/chart extraction from PDFs
- No automated document quality scoring
- No feedback loop for improving intent classification

---

## ğŸ”’ Security

**Key practices:**
- Environment variables for sensitive credentials
- CORS configuration for API security
- Input validation on all endpoints

**ğŸ“– For security details**: [See Full Publication - Section 8](INSURANCE_RAG_PUBLICATION.md#8-security-best-practices)

---
## ğŸ“„ License

This project is licensed under the **MIT License**. See [LICENSE.txt](LICENSE.txt) for details.

```
MIT License

Copyright (c) 2025 [Your Organization]

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

---

## ğŸ“ Support & Contact

### Getting Help

- **Email**: myuvaranjani@gmail.com
- **Issues**: Open an issue on GitHub repository
- **Documentation**: Check this README.md

### Contributing

We welcome contributions! Please follow these steps:

1. **Fork the repository**
2. **Create a feature branch**: `git checkout -b feature/amazing-feature`
3. **Make your changes** with clear commit messages
4. **Add tests** for new functionality
5. **Update documentation** as needed
6. **Submit a pull request** with detailed description

### Reporting Issues

When reporting issues, please include:
- Python version
- Operating system
- Error messages and stack traces
- Steps to reproduce
- Expected vs actual behavior
- Relevant logs from `backend/logs/app.log`

---

## ğŸ“ Additional Resources

- [Django Documentation](https://docs.djangoproject.com/)
- [Streamlit Documentation](https://docs.streamlit.io/)
- [LangChain Documentation](https://python.langchain.com/)
- [ChromaDB Documentation](https://docs.trychroma.com/)
- [Azure OpenAI Documentation](https://learn.microsoft.com/en-us/azure/ai-services/openai/)

---

## ğŸ™ Acknowledgments

- **Azure OpenAI**: For providing enterprise-grade AI models
- **LangChain**: For the RAG framework and utilities
- **ChromaDB**: For vector database capabilities
- **Streamlit**: For rapid UI development
- **Django**: For robust backend framework
